{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c43ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, clone_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, matthews_corrcoef, roc_auc_score, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from math import comb\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=== 10-FOLD CROSS-VALIDATION ENSEMBLE F1-SCORE DQN OPTIMIZATION WITH DIRECT VOTING ===\")\n",
    "print(\"Focus: 10-fold CV with proper data flow + Direct model-level voting ensemble\")\n",
    "print(\"Training: DQN optimizes on fold validation data\")\n",
    "print(\"Learning Curve: Uses independent validation/test split within each fold\")\n",
    "print(\"Final Evaluation: Uses external validation dataset\")\n",
    "print(\"CRITICAL UPDATE: Models are retrained on each fold's training data\")\n",
    "\n",
    "# Calculate and display the number of possible combinations\n",
    "print(\"\\nðŸ”¢ COMBINATORIAL ANALYSIS:\")\n",
    "total_models = 36\n",
    "print(f\"Total models available: {total_models}\")\n",
    "\n",
    "total_combinations = 2**36 - 1\n",
    "print(f\"Total possible ensemble combinations: {total_combinations:,}\")\n",
    "print(f\"In scientific notation: {total_combinations:.2e}\")\n",
    "\n",
    "# 36-BIT MODEL SELECTION STRUCTURE\n",
    "print(\"\\nðŸ”¢ 36-BIT MODEL SELECTION STRUCTURE:\")\n",
    "print(\"   Bits 0-11:  Group 1 Models (Models 1-12 on Dataset 1)\")\n",
    "print(\"   Bits 12-23: Group 2 Models (Models 1-12 on Dataset 2)\")\n",
    "print(\"   Bits 24-35: Group 3 Models (Models 1-12 on Dataset 3)\")\n",
    "print(\"   Structure: [Group1: 000000000000][Group2: 000000000000][Group3: 000000000000]\")\n",
    "\n",
    "# =============================================================================\n",
    "# DATA PREPARATION FOR 10-FOLD CROSS-VALIDATION\n",
    "# =============================================================================\n",
    "def prepare_10fold_datasets(original_datasets):\n",
    "    \"\"\"\n",
    "    Combine train and test data, create 10-fold splits\n",
    "    Keep external data separate for final evaluation\n",
    "    \"\"\"\n",
    "    combined_datasets = []\n",
    "    external_datasets = []\n",
    "    \n",
    "    for group_idx in range(3):\n",
    "        X_train, X_test, y_train, y_test, X_external, y_external = original_datasets[group_idx]\n",
    "        \n",
    "        # Combine train and test data\n",
    "        X_combined = np.concatenate([X_train, X_test], axis=0)\n",
    "        y_combined = np.concatenate([y_train, y_test], axis=0)\n",
    "        \n",
    "        combined_datasets.append((X_combined, y_combined))\n",
    "        external_datasets.append((X_external, y_external))\n",
    "        \n",
    "        print(f\"Group {group_idx + 1}: Combined {len(X_combined)} samples, External {len(X_external)} samples\")\n",
    "    \n",
    "    return combined_datasets, external_datasets\n",
    "\n",
    "# CRITICAL: Before running this code, you must define the following variables:\n",
    "# \n",
    "# Models (36 total):\n",
    "# model1, model1c1, model1c2, model1c3, model1c4,\n",
    "# model2, model2c1, model2c2, model2c3, model2c4, model2c5, model2c6,\n",
    "# model3, model3c1, model3c2, model3c3, model3c4,\n",
    "# model4, model4c1, model4c2, model4c3, model4c4, model4c5, model4c6,\n",
    "# model5, model5c1, model5c2, model5c3, model5c4,\n",
    "# model6, model6c1, model6c2, model6c3, model6c4, model6c5, model6c6\n",
    "#\n",
    "# Datasets (3 groups with train/test/external splits):\n",
    "# X_train_1, X_test_1, y_train_1, y_test_1, X_external_1, y_external_1\n",
    "# X_train_2, X_test_2, y_train_2, y_test_2, X_external_2, y_external_2  \n",
    "# X_train_3, X_test_3, y_train_3, y_test_3, X_external_3, y_external_3\n",
    "\n",
    "# Your real models - using the exact names from your original code\n",
    "models_group_1 = [\n",
    "     model1, model1c1, model1c2, model1c3, model1c4,\n",
    "     model2, model2c1, model2c2, model2c3, model2c4, model2c5, model2c6\n",
    "]\n",
    "models_group_2 = [\n",
    "     model3, model3c1, model3c2, model3c3, model3c4,\n",
    "     model4, model4c1, model4c2, model4c3, model4c4, model4c5, model4c6\n",
    "]\n",
    "models_group_3 = [\n",
    "     model5, model5c1, model5c2, model5c3, model5c4,\n",
    "     model6, model6c1, model6c2, model6c3, model6c4, model6c5, model6c6\n",
    "]\n",
    "original_model_templates = models_group_1 + models_group_2 + models_group_3\n",
    "\n",
    "# Prepare datasets for 10-fold CV\n",
    "original_datasets = [\n",
    "     (X_train_1, X_test_1, y_train_1, y_test_1, X_external_1, y_external_1),  # Group 1\n",
    "     (X_train_2, X_test_2, y_train_2, y_test_2, X_external_2, y_external_2),  # Group 2\n",
    "     (X_train_3, X_test_3, y_train_3, y_test_3, X_external_3, y_external_3)   # Group 3\n",
    "]\n",
    "\n",
    "combined_datasets, external_datasets = prepare_10fold_datasets(original_datasets)\n",
    "\n",
    "print(f\"\\nâœ… 10-FOLD CV DATA FLOW:\")\n",
    "print(f\"âœ“ Combined datasets: {len(combined_datasets)} groups\")\n",
    "print(f\"âœ“ External datasets: {len(external_datasets)} groups\")\n",
    "print(f\"âœ“ CV Strategy: 10-fold with proper data separation\")\n",
    "print(f\"âœ“ Model Training: Models retrained on each fold's training data (70%)\")\n",
    "print(f\"âœ“ DQN Training: Uses dedicated DQN validation data (10%)\")\n",
    "print(f\"âœ“ Learning Curve: Uses independent validation/test split (10% + 10%)\")\n",
    "print(f\"âœ“ Final Evaluation: Uses X_external (completely untouched)\")\n",
    "print(f\"âœ“ Voting Ensemble: Each selected model gets one vote per sample\")\n",
    "\n",
    "# =============================================================================\n",
    "# FOLD DATA PREPARATION FUNCTION WITH PROPER SEPARATION\n",
    "# =============================================================================\n",
    "def create_fold_datasets(combined_datasets, n_folds=10, random_state=42):\n",
    "    \"\"\"\n",
    "    Create stratified k-fold splits with proper data separation\n",
    "    Each fold: 90% train, 10% test\n",
    "    Training portion split into: 70% model training, 10% DQN validation, 10% learning curve validation\n",
    "    Test portion used for: learning curve test\n",
    "    \"\"\"\n",
    "    fold_datasets = []\n",
    "    \n",
    "    # Create stratified k-fold splitter\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Use labels from first group (all groups have identical labels)\n",
    "    X_combined_group1, y_combined_group1 = combined_datasets[0]\n",
    "    \n",
    "    # Generate fold indices\n",
    "    fold_indices = list(skf.split(X_combined_group1, y_combined_group1))\n",
    "    \n",
    "    for fold_idx, (train_indices, test_indices) in enumerate(fold_indices):\n",
    "        fold_data = {}\n",
    "        \n",
    "        for group_idx in range(3):\n",
    "            X_combined, y_combined = combined_datasets[group_idx]\n",
    "            \n",
    "            # Split into training (90%) and test (10%) for this fold\n",
    "            X_train_fold = X_combined[train_indices]\n",
    "            y_train_fold = y_combined[train_indices]\n",
    "            X_test_fold = X_combined[test_indices]\n",
    "            y_test_fold = y_combined[test_indices]\n",
    "            \n",
    "            # Further split training data (90%) into three parts:\n",
    "            # - Model Training: 70% of total data (77.78% of training portion)\n",
    "            # - DQN Validation: 10% of total data (11.11% of training portion)\n",
    "            # - Learning Curve Validation: 10% of total data (11.11% of training portion)\n",
    "            \n",
    "            total_train_size = len(X_train_fold)\n",
    "            model_training_size = int(0.7778 * total_train_size)  # 70%/90% = 0.7778\n",
    "            dqn_validation_size = int(0.1111 * total_train_size)   # 10%/90% = 0.1111\n",
    "            # Remaining goes to learning curve validation\n",
    "            \n",
    "            # Split training data\n",
    "            X_model_training = X_train_fold[:model_training_size]\n",
    "            y_model_training = y_train_fold[:model_training_size]\n",
    "            \n",
    "            X_dqn_validation = X_train_fold[model_training_size:model_training_size + dqn_validation_size]\n",
    "            y_dqn_validation = y_train_fold[model_training_size:model_training_size + dqn_validation_size]\n",
    "            \n",
    "            X_learning_curve_validation = X_train_fold[model_training_size + dqn_validation_size:]\n",
    "            y_learning_curve_validation = y_train_fold[model_training_size + dqn_validation_size:]\n",
    "            \n",
    "            # Test data for learning curve\n",
    "            X_learning_curve_test = X_test_fold\n",
    "            y_learning_curve_test = y_test_fold\n",
    "            \n",
    "            fold_data[group_idx] = {\n",
    "                'model_training': (X_model_training, y_model_training),\n",
    "                'dqn_validation': (X_dqn_validation, y_dqn_validation),  # For DQN rewards ONLY\n",
    "                'learning_curve_validation': (X_learning_curve_validation, y_learning_curve_validation),  # For learning curve validation\n",
    "                'learning_curve_test': (X_learning_curve_test, y_learning_curve_test)  # For learning curve test\n",
    "            }\n",
    "        \n",
    "        fold_datasets.append(fold_data)\n",
    "    \n",
    "    return fold_datasets\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL RETRAINING FUNCTION FOR EACH FOLD (WITH PROGRESS DISPLAY)\n",
    "# =============================================================================\n",
    "def retrain_models_for_fold(original_model_templates, fold_datasets, fold_idx, epochs=50, batch_size=32):\n",
    "    \"\"\"\n",
    "    Retrain all 36 models on the current fold's model_training data\n",
    "    Returns list of 36 retrained models\n",
    "    Shows epoch and F1 score during training\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"FOLD {fold_idx + 1}/10: RETRAINING 36 MODELS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    retrained_models = []\n",
    "    \n",
    "    for model_idx, original_model in enumerate(original_model_templates):\n",
    "        group_idx = model_idx // 12\n",
    "        \n",
    "        # Get fold-specific training data\n",
    "        X_train, y_train = fold_datasets[fold_idx][group_idx]['model_training']\n",
    "        \n",
    "        # Reshape data based on group\n",
    "        if group_idx == 0:\n",
    "            X_train_reshaped = X_train.reshape(-1, 150, 1)\n",
    "        elif group_idx == 1:\n",
    "            X_train_reshaped = X_train.reshape(-1, 84, 1)\n",
    "        else:\n",
    "            X_train_reshaped = X_train.reshape(-1, 420, 1)\n",
    "        \n",
    "        # Clone the original model architecture\n",
    "        try:\n",
    "            new_model = clone_model(original_model)\n",
    "            new_model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                new_model = tf.keras.models.model_from_json(original_model.to_json())\n",
    "                new_model.compile(\n",
    "                    optimizer='adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy']\n",
    "                )\n",
    "            except:\n",
    "                new_model = clone_model(original_model)\n",
    "                new_model.compile(\n",
    "                    optimizer=Adam(learning_rate=0.001),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy']\n",
    "                )\n",
    "        \n",
    "        # Train the model on fold-specific data with custom callback for display\n",
    "        print(f\"\\nModel {model_idx + 1}/36 (Group {group_idx + 1}):\", end=\" \")\n",
    "        \n",
    "        history = new_model.fit(\n",
    "        X_train_reshaped, \n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stop]  # Add this line\n",
    "        )\n",
    "        \n",
    "        # Get final epoch metrics\n",
    "        final_val_loss = history.history['val_loss'][-1]\n",
    "        final_val_acc = history.history['val_accuracy'][-1]\n",
    "        \n",
    "        # Calculate F1 score on validation data\n",
    "        val_size = int(0.1 * len(X_train_reshaped))\n",
    "        X_val = X_train_reshaped[-val_size:]\n",
    "        y_val = y_train[-val_size:]\n",
    "        \n",
    "        y_pred_prob = new_model.predict(X_val, verbose=0).flatten()\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "        val_f1 = f1_score(y_val, y_pred, average='binary', zero_division=0)\n",
    "        \n",
    "        print(f\"Epochs={epochs}, Val_Loss={final_val_loss:.4f}, Val_Acc={final_val_acc:.4f}, Val_F1={val_f1:.4f}\")\n",
    "        \n",
    "        retrained_models.append(new_model)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"âœ… All 36 models retrained for Fold {fold_idx + 1}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    return retrained_models\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALIZATION FUNCTIONS (SINGLE AGGREGATED LEARNING CURVES)\n",
    "# =============================================================================\n",
    "def create_aggregated_ensemble_training_plots(all_fold_rewards, all_fold_best_rewards, all_fold_f1_scores, all_fold_sizes):\n",
    "    \"\"\"Create single aggregated training reward curve with confidence intervals\"\"\"\n",
    "\n",
    "    # Find the minimum length across all folds to ensure consistent aggregation\n",
    "    min_length = min(len(rewards) for rewards in all_fold_rewards)\n",
    "    \n",
    "    # Truncate all arrays to minimum length\n",
    "    truncated_rewards = [rewards[:min_length] for rewards in all_fold_rewards]\n",
    "    truncated_best_rewards = [best_rewards[:min_length] for best_rewards in all_fold_best_rewards]\n",
    "    \n",
    "    # Convert to numpy arrays for easier computation\n",
    "    rewards_array = np.array(truncated_rewards)\n",
    "    best_rewards_array = np.array(truncated_best_rewards)\n",
    "    \n",
    "    # Calculate mean and std across folds\n",
    "    mean_rewards = np.mean(rewards_array, axis=0)\n",
    "    std_rewards = np.std(rewards_array, axis=0)\n",
    "    mean_best_rewards = np.mean(best_rewards_array, axis=0)\n",
    "    \n",
    "    episodes = range(min_length)\n",
    "    \n",
    "    plt.figure(figsize=(3.5, 2.5))\n",
    "    \n",
    "    # Plot episode rewards with confidence interval\n",
    "    plt.plot(episodes, mean_rewards, alpha=0.3, color='lightblue', label='Episode Rewards')\n",
    "    plt.fill_between(episodes, mean_rewards - std_rewards, mean_rewards + std_rewards, \n",
    "                     alpha=0.2, color='lightblue')\n",
    "    \n",
    "    # Plot best reward so far\n",
    "    plt.plot(episodes, mean_best_rewards, color='red', linewidth=1, label='Best Reward So Far')\n",
    "    \n",
    "    # Moving average\n",
    "    window_size = min(100, min_length // 2)\n",
    "    if min_length >= window_size:\n",
    "        moving_avg = np.convolve(mean_rewards, np.ones(window_size)/window_size, mode='valid')\n",
    "        plt.plot(range(window_size-1, min_length), moving_avg, 'blue', linewidth=1, label='Moving Average')\n",
    "\n",
    "    # Add convergence line\n",
    "    if len(mean_best_rewards) > 50:\n",
    "        final_reward = mean_best_rewards[-1]\n",
    "        convergence_threshold = final_reward * 0.99\n",
    "\n",
    "        convergence_episode = None\n",
    "        for i in range(len(mean_best_rewards)-1, 0, -1):\n",
    "            if mean_best_rewards[i] < convergence_threshold:\n",
    "                convergence_episode = i + 1\n",
    "                break\n",
    "\n",
    "        if convergence_episode:\n",
    "            plt.axvline(x=convergence_episode, color='green', linestyle=':', linewidth=2,\n",
    "                        label=f'Convergence (~Ep {convergence_episode})')\n",
    "\n",
    "    plt.legend(fontsize=7.5, loc='lower right')\n",
    "    plt.xlabel('Episode', fontsize=9, fontweight='bold')\n",
    "    plt.ylabel('Reward', fontsize=9, fontweight='bold')\n",
    "    plt.title('Ensemble Reward Convergence', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0.4, 1.0)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('C:/Users/lenovo/Desktop/MY Work/Paper 4/image/Revision/Layer1_Reward.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def create_aggregated_dqn_learning_plots(all_fold_agents, all_fold_f1_scores):\n",
    "    \"\"\"Create single aggregated DQN learning curves\"\"\"\n",
    "\n",
    "    # Aggregate loss histories\n",
    "    all_loss_histories = [agent.loss_history for agent in all_fold_agents if len(agent.loss_history) > 0]\n",
    "    all_epsilon_histories = [agent.epsilon_history for agent in all_fold_agents if len(agent.epsilon_history) > 0]\n",
    "    all_q_value_histories = [agent.q_value_history for agent in all_fold_agents if len(agent.q_value_history) > 0]\n",
    "\n",
    "    # Plot 1: Aggregated DQN Training Loss\n",
    "    plt.figure(figsize=(3, 2.5))\n",
    "    if len(all_loss_histories) > 0:\n",
    "        min_loss_length = min(len(loss_hist) for loss_hist in all_loss_histories)\n",
    "        if min_loss_length > 0:\n",
    "            truncated_loss = [loss_hist[:min_loss_length] for loss_hist in all_loss_histories]\n",
    "            loss_array = np.array(truncated_loss)\n",
    "            mean_loss = np.mean(loss_array, axis=0)\n",
    "            std_loss = np.std(loss_array, axis=0)\n",
    "            \n",
    "            steps = range(min_loss_length)\n",
    "            plt.plot(steps, mean_loss, alpha=0.7, color='red', linewidth=1)\n",
    "            plt.fill_between(steps, mean_loss - std_loss, mean_loss + std_loss, \n",
    "                           alpha=0.3, color='red')\n",
    "\n",
    "            if min_loss_length >= 50:\n",
    "                window_size = 50\n",
    "                moving_avg = np.convolve(mean_loss, np.ones(window_size) / window_size, mode='valid')\n",
    "                plt.plot(range(window_size - 1, min_loss_length), moving_avg,\n",
    "                         'darkred', linewidth=1, label='Moving Average (50)')\n",
    "                plt.legend(fontsize=7.5, loc='upper right')\n",
    "            \n",
    "            plt.xlabel('Training Step', fontsize=9, fontweight='bold')\n",
    "            plt.ylabel('DQN Loss (MSE)', fontsize=9, fontweight='bold')\n",
    "            plt.title('DQN Training Loss', fontsize=9, fontweight='bold')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            if np.max(mean_loss) > 100:\n",
    "                plt.yscale('log')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No Loss Data Available', ha='center', va='center',\n",
    "                 transform=plt.gca().transAxes, fontsize=10)\n",
    "        plt.title('DQN Training Loss', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('C:/Users/lenovo/Desktop/MY Work/Paper 4/image/Revision/Layer1_DQN_Loss.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 2: Aggregated Epsilon Decay\n",
    "    plt.figure(figsize=(3, 2.5))\n",
    "    if len(all_epsilon_histories) > 0:\n",
    "        min_epsilon_length = min(len(eps_hist) for eps_hist in all_epsilon_histories)\n",
    "        if min_epsilon_length > 0:\n",
    "            truncated_epsilon = [eps_hist[:min_epsilon_length] for eps_hist in all_epsilon_histories]\n",
    "            epsilon_array = np.array(truncated_epsilon)\n",
    "            mean_epsilon = np.mean(epsilon_array, axis=0)\n",
    "            \n",
    "            steps = range(min_epsilon_length)\n",
    "            plt.plot(steps, mean_epsilon, alpha=0.8, color='blue', linewidth=1.2)\n",
    "            plt.xlabel('Training Step', fontsize=9, fontweight='bold')\n",
    "            plt.ylabel('Epsilon (Exploration Rate)', fontsize=9, fontweight='bold')\n",
    "            plt.title('Epsilon Decay', fontsize=9, fontweight='bold')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            plt.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='Îµ = 0.5')\n",
    "            plt.axhline(y=0.1, color='green', linestyle='--', alpha=0.5, label='Îµ = 0.1')\n",
    "            plt.axhline(y=0.01, color='red', linestyle='--', alpha=0.5, label='Îµ = 0.01 (min)')\n",
    "            plt.legend(fontsize=8)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No Epsilon Data Available', ha='center', va='center',\n",
    "                 transform=plt.gca().transAxes, fontsize=10)\n",
    "        plt.title('Epsilon Decay', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('C:/Users/lenovo/Desktop/MY Work/Paper 4/image/Revision/Layer1_Epsilon_decay.pdf')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 3: Aggregated Q-Value Learning\n",
    "    plt.figure(figsize=(3, 2.5))\n",
    "    if len(all_q_value_histories) > 0:\n",
    "        min_q_length = min(len(q_hist) for q_hist in all_q_value_histories)\n",
    "        if min_q_length > 0:\n",
    "            truncated_q = [q_hist[:min_q_length] for q_hist in all_q_value_histories]\n",
    "            q_array = np.array(truncated_q)\n",
    "            mean_q = np.mean(q_array, axis=0)\n",
    "            std_q = np.std(q_array, axis=0)\n",
    "            \n",
    "            episodes = range(min_q_length)\n",
    "            plt.plot(episodes, mean_q, alpha=0.6, color='purple', label='Max Q-Value')\n",
    "            plt.fill_between(episodes, mean_q - std_q, mean_q + std_q, \n",
    "                           alpha=0.3, color='purple')\n",
    "\n",
    "            window_size = min(50, min_q_length // 2)\n",
    "            if min_q_length >= window_size:\n",
    "                q_moving_avg = np.convolve(mean_q, np.ones(window_size) / window_size, mode='valid')\n",
    "                plt.plot(range(window_size - 1, min_q_length), q_moving_avg,\n",
    "                         'black', linewidth=1, label='Max Q-Value (50)')\n",
    "\n",
    "            plt.xlabel('Episode', fontsize=9, fontweight='bold')\n",
    "            plt.ylabel('Q-Value', fontsize=9, fontweight='bold')\n",
    "            plt.title('Q-Value Learning', fontsize=9, fontweight='bold')\n",
    "            plt.legend(fontsize=7.5, loc='lower right')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No Q-Value Data Available', ha='center', va='center',\n",
    "                 transform=plt.gca().transAxes, fontsize=10)\n",
    "        plt.title('Q-Value Learning', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('C:/Users/lenovo/Desktop/MY Work/Paper 4/image/Revision/Layer1_Q_Value.pdf')\n",
    "    plt.show()\n",
    "\n",
    "def create_aggregated_f1_learning_curve(all_fold_validation_f1, all_fold_test_f1, all_evaluation_episodes):\n",
    "    \"\"\"Create single aggregated F1 learning curve showing validation vs test F1 scores\"\"\"\n",
    "    \n",
    "    # Find minimum length across all folds\n",
    "    min_length = min(len(val_f1) for val_f1 in all_fold_validation_f1 if len(val_f1) > 0)\n",
    "    \n",
    "    if min_length == 0:\n",
    "        print(\"No F1 data available for learning curve\")\n",
    "        return\n",
    "    \n",
    "    # Truncate and aggregate F1 scores\n",
    "    truncated_val_f1 = [val_f1[:min_length] for val_f1 in all_fold_validation_f1 if len(val_f1) >= min_length]\n",
    "    truncated_test_f1 = [test_f1[:min_length] for test_f1 in all_fold_test_f1 if len(test_f1) >= min_length]\n",
    "    \n",
    "    if len(truncated_val_f1) == 0 or len(truncated_test_f1) == 0:\n",
    "        print(\"Insufficient F1 data for aggregation\")\n",
    "        return\n",
    "    \n",
    "    val_f1_array = np.array(truncated_val_f1)\n",
    "    test_f1_array = np.array(truncated_test_f1)\n",
    "    \n",
    "    mean_val_f1 = np.mean(val_f1_array, axis=0)\n",
    "    std_val_f1 = np.std(val_f1_array, axis=0)\n",
    "    mean_test_f1 = np.mean(test_f1_array, axis=0)\n",
    "    std_test_f1 = np.std(test_f1_array, axis=0)\n",
    "    \n",
    "    # Use episodes from first fold (should be consistent across folds)\n",
    "    episodes = all_evaluation_episodes[0][:min_length]\n",
    "    \n",
    "    plt.figure(figsize=(3, 2.5))\n",
    "    \n",
    "    # Plot validation and test F1 scores with confidence intervals\n",
    "    plt.plot(episodes, mean_val_f1, alpha=0.7, color='blue', linewidth=0.5, label='Ensemble Validation F1')\n",
    "    plt.fill_between(episodes, mean_val_f1 - std_val_f1, mean_val_f1 + std_val_f1, \n",
    "                     alpha=0.3, color='blue')\n",
    "    \n",
    "    plt.plot(episodes, mean_test_f1, alpha=0.7, color='red', linewidth=0.5, label='Ensemble Test F1')\n",
    "    plt.fill_between(episodes, mean_test_f1 - std_test_f1, mean_test_f1 + std_test_f1, \n",
    "                     alpha=0.3, color='red')\n",
    "    \n",
    "    # Legend with font size\n",
    "    plt.legend(fontsize=7.5, loc='lower right')\n",
    "    \n",
    "    plt.xlabel('Episode', fontsize=9, fontweight='bold')\n",
    "    plt.ylabel('F1 Score', fontsize=9, fontweight='bold')\n",
    "    plt.title('Validation vs Test F1 Score Validation', fontsize=9, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.ylim(0.0, 1.0)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('C:/Users/lenovo/Desktop/MY Work/Paper 4/image/Revision/Layer1_F1_validation.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    # Analysis across all folds\n",
    "    print(f\"\\nF1 LEARNING CURVE ANALYSIS:\")\n",
    "    if len(mean_val_f1) > 0 and len(mean_test_f1) > 0:\n",
    "        final_validation_f1 = mean_val_f1[-1]\n",
    "        final_test_f1 = mean_test_f1[-1]\n",
    "        final_gap = abs(final_validation_f1 - final_test_f1)\n",
    "        \n",
    "        print(f\"   Final Validation F1: {final_validation_f1:.4f}\")\n",
    "        print(f\"   Final Test F1: {final_test_f1:.4f}\")\n",
    "        print(f\"   Final Gap: {final_gap:.4f}\")\n",
    "        \n",
    "        if final_gap < 0.05:\n",
    "            print(f\"   STATUS: No overfitting - Good generalization\")\n",
    "        elif final_gap < 0.10:\n",
    "            print(f\"   STATUS: Slight overfitting - Acceptable\")\n",
    "        else:\n",
    "            print(f\"   STATUS: Overfitting detected - Poor generalization\")\n",
    "\n",
    "# =============================================================================\n",
    "# DIRECT MODEL-LEVEL VOTING ENSEMBLE FUNCTION\n",
    "# =============================================================================\n",
    "def evaluate_direct_voting_ensemble_on_external_data(evaluator, selected_indices, external_datasets):\n",
    "    \"\"\"\n",
    "    Direct voting ensemble: Each selected model gets one vote per sample\n",
    "    \"\"\"\n",
    "    if len(selected_indices) == 0:\n",
    "        return None\n",
    "    \n",
    "    valid_selected = [i for i in selected_indices if i in evaluator.valid_models]\n",
    "    if len(valid_selected) == 0:\n",
    "        return None\n",
    "    \n",
    "    print(f\"Direct voting ensemble with {len(valid_selected)} models: {valid_selected}\")\n",
    "    \n",
    "    # Collect votes from all selected models\n",
    "    all_model_votes = []\n",
    "    all_model_probabilities = []\n",
    "    unified_true_labels = None\n",
    "    \n",
    "    for model_idx in valid_selected:\n",
    "        group_idx = model_idx // 12\n",
    "        \n",
    "        # Get the external dataset for this model's group\n",
    "        X_external, y_external = external_datasets[group_idx]\n",
    "        \n",
    "        # Store true labels (same across all datasets)\n",
    "        if unified_true_labels is None:\n",
    "            unified_true_labels = y_external.copy()\n",
    "        \n",
    "        # Reshape external data based on the group's feature dimensions\n",
    "        if group_idx == 0:\n",
    "            X_external_reshaped = X_external.reshape(-1, 150, 1)\n",
    "        elif group_idx == 1:\n",
    "            X_external_reshaped = X_external.reshape(-1, 84, 1)\n",
    "        else:\n",
    "            X_external_reshaped = X_external.reshape(-1, 420, 1)\n",
    "        \n",
    "        try:\n",
    "            model = evaluator.models[model_idx]\n",
    "            \n",
    "            # Get probability predictions\n",
    "            pred_prob = model.predict(X_external_reshaped, verbose=0).flatten()\n",
    "            \n",
    "            # Convert to binary vote (0 or 1)\n",
    "            model_vote = (pred_prob > 0.5).astype(int)\n",
    "            \n",
    "            all_model_votes.append(model_vote)\n",
    "            all_model_probabilities.append(pred_prob)\n",
    "            print(f\"  âœ“ Model {model_idx} (Group {group_idx + 1}): {len(model_vote)} votes collected\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— Model {model_idx} failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if len(all_model_votes) == 0:\n",
    "        print(\"ERROR: No valid model votes!\")\n",
    "        return None\n",
    "    \n",
    "    # Direct majority voting across all selected models\n",
    "    all_votes = np.array(all_model_votes)\n",
    "    all_probs = np.array(all_model_probabilities)\n",
    "    \n",
    "    # Count votes for each sample\n",
    "    positive_votes = np.sum(all_votes, axis=0)\n",
    "    total_models = len(all_model_votes)\n",
    "    \n",
    "    # Majority rule: if more than half vote positive, predict positive\n",
    "    final_predictions = (positive_votes > total_models / 2).astype(int)\n",
    "    \n",
    "    # Average probabilities for ROC-AUC and PR curves\n",
    "    ensemble_probabilities = np.mean(all_probs, axis=0)\n",
    "    \n",
    "    print(f\"\\nDirect Voting Results:\")\n",
    "    print(f\"â”œâ”€ Total models voting: {total_models}\")\n",
    "    print(f\"â”œâ”€ Samples: {len(final_predictions)}\")\n",
    "    print(f\"â”œâ”€ Vote distribution per sample: min={np.min(positive_votes)}, max={np.max(positive_votes)}\")\n",
    "    print(f\"â””â”€ Final predictions: {np.bincount(final_predictions)}\")\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(unified_true_labels, final_predictions)\n",
    "    f1 = f1_score(unified_true_labels, final_predictions, average='binary', zero_division=0)\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(unified_true_labels, final_predictions)\n",
    "    \n",
    "    # Enhanced visualization with larger figure size\n",
    "    plt.figure(figsize=(2.5, 2.5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'10-Fold CV Direct Voting Ensemble CM', \n",
    "              fontweight='bold', fontsize=9)\n",
    "    plt.xlabel('Predicted Label', fontweight='bold', fontsize=9)\n",
    "    plt.ylabel('True Label', fontweight='bold', fontsize=9)\n",
    "    plt.xticks([0.5, 1.5], ['Negative (0)', 'Positive (1)'], fontsize=8)\n",
    "    plt.yticks([0.5, 1.5], ['Negative (0)', 'Positive (1)'], fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create ROC-AUC curve\n",
    "    plt.figure(figsize=(3, 2.5))\n",
    "    fpr, tpr, roc_thresholds = roc_curve(unified_true_labels, ensemble_probabilities)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='red', lw=1, linestyle='--', label='Random Classifier')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontweight='bold', fontsize=9)\n",
    "    plt.ylabel('True Positive Rate', fontweight='bold', fontsize=9)\n",
    "    plt.title('10-Fold CV ROC-AUC Curve (External Data)', fontweight='bold', fontsize=9)\n",
    "    plt.legend(loc=\"lower right\", fontsize=8)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('C:/Users/lenovo/Desktop/MY Work/Paper 4/image/Revision/Layer1_10Fold_ROC_AUC.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create Precision-Recall curve\n",
    "    plt.figure(figsize=(3, 2.5))\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(unified_true_labels, ensemble_probabilities)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    plt.plot(recall, precision, color='green', lw=2, label=f'PR Curve (AUC = {pr_auc:.3f})')\n",
    "    \n",
    "    # Calculate baseline (random classifier performance)\n",
    "    positive_ratio = np.sum(unified_true_labels) / len(unified_true_labels)\n",
    "    plt.axhline(y=positive_ratio, color='red', linestyle='--', lw=1, \n",
    "                label=f'Random Classifier (Baseline = {positive_ratio:.3f})')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall', fontweight='bold', fontsize=9)\n",
    "    plt.ylabel('Precision', fontweight='bold', fontsize=9)\n",
    "    plt.title('10-Fold CV Precision-Recall Curve (External Data)', fontweight='bold', fontsize=9)\n",
    "    plt.legend(loc=\"lower left\", fontsize=8)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('C:/Users/lenovo/Desktop/MY Work/Paper 4/image/Revision/Layer1_10Fold_PR_Curve.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    # Enhanced detailed analysis with additional error metrics\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        total_samples = tn + fp + fn + tp\n",
    "        \n",
    "        # Basic metrics\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        \n",
    "        # Additional error analysis metrics\n",
    "        total_errors = fp + fn\n",
    "        error_rate = total_errors / total_samples if total_samples > 0 else 0\n",
    "        false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "        \n",
    "        print(f\"\\n10-FOLD CV DIRECT VOTING ENSEMBLE ANALYSIS:\")\n",
    "        print(f\"â”œâ”€ True Negatives (TN):   {tn:4d}\")\n",
    "        print(f\"â”œâ”€ False Positives (FP):  {fp:4d}\")\n",
    "        print(f\"â”œâ”€ False Negatives (FN):  {fn:4d}\")\n",
    "        print(f\"â”œâ”€ True Positives (TP):   {tp:4d}\")\n",
    "        print(f\"â””â”€ Total Samples:         {total_samples}\")\n",
    "        \n",
    "        print(f\"\\nPerformance Metrics:\")\n",
    "        print(f\"â”œâ”€ Accuracy:              {accuracy:.4f}\")\n",
    "        print(f\"â”œâ”€ Sensitivity (Recall):  {sensitivity:.4f}\")\n",
    "        print(f\"â”œâ”€ Specificity:           {specificity:.4f}\")\n",
    "        print(f\"â”œâ”€ Precision (PPV):       {precision:.4f}\")\n",
    "        print(f\"â”œâ”€ F1 Score:              {f1:.4f}\")\n",
    "        print(f\"â”œâ”€ ROC-AUC:               {roc_auc:.4f}\")\n",
    "        print(f\"â””â”€ PR-AUC:                {pr_auc:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'confusion_matrix': cm,\n",
    "        'true_labels': unified_true_labels,\n",
    "        'predictions': final_predictions,\n",
    "        'probabilities': ensemble_probabilities,\n",
    "        'vote_counts': positive_votes,\n",
    "        'total_models': total_models,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc,\n",
    "        'selected_models': valid_selected\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# 10-FOLD ENSEMBLE EVALUATOR CLASS (UPDATED FOR RETRAINED MODELS)\n",
    "# =============================================================================\n",
    "class TenFoldEnsembleEvaluator:\n",
    "    \"\"\"Evaluates ensemble performance with 10-fold cross-validation\"\"\"\n",
    "    \n",
    "    def __init__(self, models, combined_datasets, fold_datasets):\n",
    "        self.models = models  # This will be updated with retrained models for each fold\n",
    "        self.combined_datasets = combined_datasets\n",
    "        self.fold_datasets = fold_datasets\n",
    "        self.valid_models = self._validate_models()\n",
    "        \n",
    "        print(f\"âœ… 10-Fold ensemble evaluator initialized with {len(self.valid_models)}/36 valid models\")\n",
    "    \n",
    "    def update_models(self, new_models):\n",
    "        \"\"\"Update models with newly retrained models for current fold\"\"\"\n",
    "        self.models = new_models\n",
    "        self.valid_models = self._validate_models()\n",
    "        \n",
    "    def _validate_models(self):\n",
    "        \"\"\"Validate which models can make predictions\"\"\"\n",
    "        valid_models = []\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            try:\n",
    "                group_idx = i // 12\n",
    "                # Use first fold's model training data for validation\n",
    "                X_train_fold = self.fold_datasets[0][group_idx]['model_training'][0]\n",
    "                \n",
    "                # Build model if not built\n",
    "                if not hasattr(model, '_built') or not model._built:\n",
    "                    try:\n",
    "                        if group_idx == 0:\n",
    "                            input_shape = (None, 150, 1)\n",
    "                        elif group_idx == 1:\n",
    "                            input_shape = (None, 84, 1)\n",
    "                        else:\n",
    "                            input_shape = (None, 420, 1)\n",
    "                        \n",
    "                        model.build(input_shape=input_shape)\n",
    "                    except Exception:\n",
    "                        try:\n",
    "                            sample_size = min(1, len(X_train_fold))\n",
    "                            if group_idx == 0:\n",
    "                                test_sample = X_train_fold[:sample_size].reshape(-1, 150, 1)\n",
    "                            elif group_idx == 1:\n",
    "                                test_sample = X_train_fold[:sample_size].reshape(-1, 84, 1)\n",
    "                            else:\n",
    "                                test_sample = X_train_fold[:sample_size].reshape(-1, 420, 1)\n",
    "                            \n",
    "                            _ = model(test_sample, training=False)\n",
    "                        except Exception:\n",
    "                            continue\n",
    "                \n",
    "                # Test prediction\n",
    "                try:\n",
    "                    sample_size = min(3, len(X_train_fold))\n",
    "                    \n",
    "                    if group_idx == 0:\n",
    "                        test_sample = X_train_fold[:sample_size].reshape(-1, 150, 1)\n",
    "                    elif group_idx == 1:\n",
    "                        test_sample = X_train_fold[:sample_size].reshape(-1, 84, 1)\n",
    "                    else:\n",
    "                        test_sample = X_train_fold[:sample_size].reshape(-1, 420, 1)\n",
    "                    \n",
    "                    test_sample = tf.constant(test_sample, dtype=tf.float32)\n",
    "                    test_pred = model(test_sample, training=False)\n",
    "                    \n",
    "                    if test_pred is not None and len(test_pred) == sample_size:\n",
    "                        valid_models.append(i)\n",
    "                    \n",
    "                except Exception:\n",
    "                    try:\n",
    "                        test_pred = model.predict(test_sample.numpy(), verbose=0)\n",
    "                        if test_pred is not None and len(test_pred) == sample_size:\n",
    "                            valid_models.append(i)\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                \n",
    "            except Exception:\n",
    "                continue\n",
    "                \n",
    "        return valid_models\n",
    "    \n",
    "    def evaluate_ensemble_for_dqn_training(self, selected_indices, fold_idx):\n",
    "        \"\"\"\n",
    "        Evaluate ensemble for DQN reward calculation\n",
    "        Uses DQN validation data - this is what DQN optimizes on\n",
    "        \"\"\"\n",
    "        if len(selected_indices) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        valid_selected = [i for i in selected_indices if i in self.valid_models]\n",
    "        if len(valid_selected) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        all_predictions = []\n",
    "        all_true_labels = []\n",
    "        \n",
    "        for group_idx in range(3):\n",
    "            group_models = [i for i in valid_selected if i // 12 == group_idx]\n",
    "            if len(group_models) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Use DQN validation data for DQN training\n",
    "            X_dqn_validation, y_dqn_validation = self.fold_datasets[fold_idx][group_idx]['dqn_validation']\n",
    "            \n",
    "            # Reshape data for this group\n",
    "            if group_idx == 0:\n",
    "                X_dqn_validation_reshaped = X_dqn_validation.reshape(-1, 150, 1)\n",
    "            elif group_idx == 1:\n",
    "                X_dqn_validation_reshaped = X_dqn_validation.reshape(-1, 84, 1)\n",
    "            else:\n",
    "                X_dqn_validation_reshaped = X_dqn_validation.reshape(-1, 420, 1)\n",
    "            \n",
    "            # Get predictions from all models in this group\n",
    "            group_predictions = []\n",
    "            for model_idx in group_models:\n",
    "                try:\n",
    "                    model = self.models[model_idx]\n",
    "                    pred_prob = model.predict(X_dqn_validation_reshaped, verbose=0).flatten()\n",
    "                    group_predictions.append(pred_prob)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            if len(group_predictions) > 0:\n",
    "                # Average predictions within group (ensemble voting)\n",
    "                ensemble_prob = np.mean(group_predictions, axis=0)\n",
    "                ensemble_pred = (ensemble_prob > 0.5).astype(int)\n",
    "                \n",
    "                all_predictions.extend(ensemble_pred)\n",
    "                all_true_labels.extend(y_dqn_validation)\n",
    "        \n",
    "        if len(all_predictions) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate F1 score for DQN reward\n",
    "        try:\n",
    "            f1 = f1_score(all_true_labels, all_predictions, average='binary', zero_division=0)\n",
    "            return f1\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    \n",
    "    def evaluate_ensemble_for_learning_curve(self, selected_indices, fold_idx):\n",
    "        \"\"\"\n",
    "        Evaluate ensemble for learning curve\n",
    "        Uses independent learning curve validation/test split within fold\n",
    "        \"\"\"\n",
    "        if len(selected_indices) == 0:\n",
    "            return 0.0, 0.0\n",
    "        \n",
    "        valid_selected = [i for i in selected_indices if i in self.valid_models]\n",
    "        if len(valid_selected) == 0:\n",
    "            return 0.0, 0.0\n",
    "        \n",
    "        # Collect predictions from learning curve validation portion\n",
    "        all_validation_predictions = []\n",
    "        all_validation_labels = []\n",
    "        \n",
    "        # Collect predictions from learning curve test portion  \n",
    "        all_test_predictions = []\n",
    "        all_test_labels = []\n",
    "        \n",
    "        for group_idx in range(3):\n",
    "            group_models = [i for i in valid_selected if i // 12 == group_idx]\n",
    "            if len(group_models) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Use independent learning curve validation/test data within fold\n",
    "            X_validation, y_validation = self.fold_datasets[fold_idx][group_idx]['learning_curve_validation']\n",
    "            X_test, y_test = self.fold_datasets[fold_idx][group_idx]['learning_curve_test']\n",
    "            \n",
    "            # Reshape data for this group\n",
    "            if group_idx == 0:\n",
    "                X_validation_reshaped = X_validation.reshape(-1, 150, 1)\n",
    "                X_test_reshaped = X_test.reshape(-1, 150, 1)\n",
    "            elif group_idx == 1:\n",
    "                X_validation_reshaped = X_validation.reshape(-1, 84, 1)\n",
    "                X_test_reshaped = X_test.reshape(-1, 84, 1)\n",
    "            else:\n",
    "                X_validation_reshaped = X_validation.reshape(-1, 420, 1)\n",
    "                X_test_reshaped = X_test.reshape(-1, 420, 1)\n",
    "            \n",
    "            # Get predictions from all models in this group\n",
    "            group_validation_predictions = []\n",
    "            group_test_predictions = []\n",
    "            \n",
    "            for model_idx in group_models:\n",
    "                try:\n",
    "                    model = self.models[model_idx]\n",
    "                    \n",
    "                    # Learning curve validation predictions\n",
    "                    validation_pred_prob = model.predict(X_validation_reshaped, verbose=0).flatten()\n",
    "                    group_validation_predictions.append(validation_pred_prob)\n",
    "                    \n",
    "                    # Learning curve test predictions\n",
    "                    test_pred_prob = model.predict(X_test_reshaped, verbose=0).flatten()\n",
    "                    group_test_predictions.append(test_pred_prob)\n",
    "                    \n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            if len(group_validation_predictions) > 0:\n",
    "                # Average predictions within group\n",
    "                ensemble_validation_prob = np.mean(group_validation_predictions, axis=0)\n",
    "                ensemble_validation_pred = (ensemble_validation_prob > 0.5).astype(int)\n",
    "                \n",
    "                ensemble_test_prob = np.mean(group_test_predictions, axis=0)\n",
    "                ensemble_test_pred = (ensemble_test_prob > 0.5).astype(int)\n",
    "                \n",
    "                all_validation_predictions.extend(ensemble_validation_pred)\n",
    "                all_validation_labels.extend(y_validation)\n",
    "                \n",
    "                all_test_predictions.extend(ensemble_test_pred)\n",
    "                all_test_labels.extend(y_test)\n",
    "        \n",
    "        if len(all_validation_predictions) == 0 or len(all_test_predictions) == 0:\n",
    "            return 0.0, 0.0\n",
    "        \n",
    "        # Calculate F1 scores for learning curve\n",
    "        try:\n",
    "            validation_f1 = f1_score(all_validation_labels, all_validation_predictions, average='binary', zero_division=0)\n",
    "            test_f1 = f1_score(all_test_labels, all_test_predictions, average='binary', zero_division=0)\n",
    "            return validation_f1, test_f1\n",
    "        except Exception:\n",
    "            return 0.0, 0.0\n",
    "\n",
    "# =============================================================================\n",
    "# DQN AGENT CLASS (UPDATED WITH STATE SIZE = 36)\n",
    "# =============================================================================\n",
    "class EnsembleDQNAgent:\n",
    "    def __init__(self, state_size=36, action_size=36, learning_rate=0.003):\n",
    "        self.state_size = state_size  # 36-bit model selection state\n",
    "        self.action_size = action_size  # 36 actions (one per model)\n",
    "        self.memory = deque(maxlen=10000)\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = 0.95\n",
    "        self.q_network = self._build_model()\n",
    "        self.target_network = self._build_model()\n",
    "        self.update_target_network()\n",
    "        \n",
    "        # Learning tracking variables\n",
    "        self.loss_history = []\n",
    "        self.epsilon_history = []\n",
    "        self.q_value_history = []\n",
    "        self.reward_history = []\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='sigmoid'))  # Sigmoid for binary decisions\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.set_weights(self.q_network.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state, valid_models_list):\n",
    "        \"\"\"\n",
    "        State: 36-bit current selection\n",
    "        Action: 36-bit new selection based on Q-values\n",
    "        \"\"\"\n",
    "        q_values = self.q_network.predict(state.reshape(1, -1), verbose=0)[0]\n",
    "        max_q_value = np.max(q_values)\n",
    "        self.q_value_history.append(max_q_value)\n",
    "        \n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # Random exploration: randomly select 3-20 models\n",
    "            action = np.zeros(36)\n",
    "            max_select = min(len(valid_models_list), 20)\n",
    "            min_select = 3\n",
    "            num_select = np.random.randint(min_select, max_select + 1)\n",
    "            selected = np.random.choice(valid_models_list, num_select, replace=False)\n",
    "            action[selected] = 1\n",
    "            return action\n",
    "        \n",
    "        # Exploitation: Use Q-values to decide inclusion/exclusion\n",
    "        action = np.zeros(36)\n",
    "        \n",
    "        # Sort valid models by their Q-values\n",
    "        valid_q_pairs = [(i, q_values[i]) for i in valid_models_list]\n",
    "        valid_q_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Select top models based on Q-values (at least 3, at most 20)\n",
    "        num_select = min(max(3, len(valid_models_list) // 2), 20)\n",
    "        \n",
    "        # Ensure diversity: select from all 3 groups\n",
    "        selected_groups = set()\n",
    "        selected_count = 0\n",
    "        \n",
    "        for idx, q_val in valid_q_pairs:\n",
    "            if selected_count >= num_select:\n",
    "                break\n",
    "                \n",
    "            group_idx = idx // 12\n",
    "            \n",
    "            # Encourage group diversity\n",
    "            if selected_count < 3 or len(selected_groups) < 3:\n",
    "                if group_idx not in selected_groups or selected_count < 3:\n",
    "                    action[idx] = 1\n",
    "                    selected_count += 1\n",
    "                    selected_groups.add(group_idx)\n",
    "            elif selected_count < num_select:\n",
    "                action[idx] = 1\n",
    "                selected_count += 1\n",
    "                selected_groups.add(group_idx)\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def replay(self, batch_size=64):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return None\n",
    "        \n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        states = np.array([e[0] for e in batch])\n",
    "        actions = np.array([e[1] for e in batch])\n",
    "        rewards = np.array([e[2] for e in batch])\n",
    "        next_states = np.array([e[3] for e in batch])\n",
    "        dones = np.array([e[4] for e in batch])\n",
    "\n",
    "        current_q_values = self.q_network.predict(states, verbose=0)\n",
    "        next_q_values = self.target_network.predict(next_states, verbose=0)\n",
    "\n",
    "        target_q_values = current_q_values.copy()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # Update Q-values for all actions based on reward\n",
    "            if dones[i]:\n",
    "                target_value = rewards[i]\n",
    "            else:\n",
    "                max_next_q = np.max(next_q_values[i])\n",
    "                target_value = rewards[i] + self.gamma * max_next_q\n",
    "            \n",
    "            # Update Q-values for selected actions\n",
    "            selected_actions = np.where(actions[i] == 1)[0]\n",
    "            for action_idx in selected_actions:\n",
    "                target_q_values[i][action_idx] = target_value\n",
    "\n",
    "        history = self.q_network.fit(states, target_q_values, epochs=1, verbose=0, batch_size=32)\n",
    "        current_loss = history.history['loss'][0]\n",
    "        self.loss_history.append(current_loss)\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "        self.epsilon_history.append(self.epsilon)\n",
    "        return current_loss\n",
    "\n",
    "    def reset_for_new_fold(self):\n",
    "        \"\"\"Reset agent state for new fold while keeping learned experience\"\"\"\n",
    "        self.epsilon = 1.0\n",
    "\n",
    "# =============================================================================\n",
    "# ENVIRONMENT CLASS (UPDATED WITH 36-BIT STATE)\n",
    "# =============================================================================\n",
    "class TenFoldEnsembleEnvironment:\n",
    "    def __init__(self, ensemble_evaluator, valid_models_list, fold_idx):\n",
    "        self.ensemble_evaluator = ensemble_evaluator\n",
    "        self.valid_models = valid_models_list\n",
    "        self.fold_idx = fold_idx\n",
    "        \n",
    "        print(f\"Environment initialized for fold {fold_idx + 1}\")\n",
    "        print(f\"Valid models: {len(self.valid_models)}\")\n",
    "        print(f\"State: 36-bit model selection vector\")\n",
    "        print(f\"Action: Include/exclude decision for each model\")\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_selection = np.zeros(36)\n",
    "        return self._get_state()\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"State representation: 36-bit current selection\"\"\"\n",
    "        return self.current_selection.copy()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Apply action: new 36-bit selection\n",
    "        Calculate reward: F1 score of new selection\n",
    "        \"\"\"\n",
    "        self.current_selection = action.copy()\n",
    "        selected_indices = np.where(action == 1)[0]\n",
    "        \n",
    "        valid_selected = [i for i in selected_indices if i in self.valid_models]\n",
    "        \n",
    "        try:\n",
    "            # Calculate reward (F1 score) for this selection\n",
    "            reward = self.ensemble_evaluator.evaluate_ensemble_for_dqn_training(valid_selected, self.fold_idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating ensemble reward: {e}\")\n",
    "            reward = 0.0\n",
    "        \n",
    "        return self._get_state(), reward, True\n",
    "# =============================================================================\n",
    "# 10-FOLD TRAINING FUNCTION (UPDATED WITH MODEL RETRAINING)\n",
    "# =============================================================================\n",
    "def train_10fold_ensemble_dqn(original_model_templates, combined_datasets, external_datasets, \n",
    "                               episodes=1000, evaluation_frequency=50, f1_curve_frequency=1, \n",
    "                               model_training_epochs=200):\n",
    "    \"\"\"Train DQN with 10-fold cross-validation - models retrained on each fold\"\"\"\n",
    "    \n",
    "    # Create fold datasets with proper separation\n",
    "    fold_datasets = create_fold_datasets(combined_datasets, n_folds=10)\n",
    "    \n",
    "    # Storage for all fold results\n",
    "    all_fold_best_selections = []\n",
    "    all_fold_best_rewards = []\n",
    "    all_fold_agents = []\n",
    "    \n",
    "    # Storage for plotting (aggregated data)\n",
    "    all_fold_rewards = []\n",
    "    all_fold_best_rewards_plot = []\n",
    "    all_fold_f1_scores = []\n",
    "    all_fold_sizes = []\n",
    "    all_fold_validation_f1 = []\n",
    "    all_fold_test_f1 = []\n",
    "    all_evaluation_episodes = []\n",
    "    \n",
    "    # Storage for final evaluation (will use best fold's retrained models)\n",
    "    best_fold_retrained_models = None\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"STARTING 10-FOLD CROSS-VALIDATION WITH MODEL RETRAINING\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Episodes per fold: {episodes}\")\n",
    "    print(f\"Model retraining epochs: {model_training_epochs}\")\n",
    "    print(f\"State representation: Only F1 score\")\n",
    "    \n",
    "    # Train on each fold\n",
    "    for fold_idx in range(10):\n",
    "        # CRITICAL: Retrain all 36 models on this fold's model_training data\n",
    "        retrained_models = retrain_models_for_fold(\n",
    "            original_model_templates, \n",
    "            fold_datasets, \n",
    "            fold_idx,\n",
    "            epochs=model_training_epochs\n",
    "        )\n",
    "        \n",
    "        # Initialize evaluator with retrained models for this fold\n",
    "        evaluator = TenFoldEnsembleEvaluator(retrained_models, combined_datasets, fold_datasets)\n",
    "        valid_models_list = evaluator.valid_models\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"FOLD {fold_idx + 1}/10: DQN ENSEMBLE OPTIMIZATION\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Initialize environment and agent for this fold\n",
    "        env = TenFoldEnsembleEnvironment(evaluator, valid_models_list, fold_idx)\n",
    "        \n",
    "        agent = EnsembleDQNAgent(state_size=36, action_size=36)  # state_size=36\n",
    "        \n",
    "        # Reset agent for new fold (optional transfer learning)\n",
    "        if fold_idx > 0:\n",
    "            agent.reset_for_new_fold()\n",
    "        \n",
    "        best_selection = np.zeros(36)\n",
    "        best_reward = -float('inf')\n",
    "        best_episode = 0\n",
    "        \n",
    "        episode_rewards = []\n",
    "        episode_best_rewards = []\n",
    "        episode_f1_scores = []\n",
    "        episode_sizes = []\n",
    "        \n",
    "        # F1 learning curve tracking for this fold\n",
    "        episode_validation_f1 = []\n",
    "        episode_test_f1 = []\n",
    "        f1_evaluation_episodes = []\n",
    "        \n",
    "        # Train for this fold\n",
    "        for episode in range(episodes):\n",
    "            state = env.reset()\n",
    "            \n",
    "            action = agent.act(state, valid_models_list)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            \n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            \n",
    "            episode_rewards.append(reward)\n",
    "            agent.reward_history.append(reward)\n",
    "            \n",
    "            selected_count = int(np.sum(action))\n",
    "            episode_sizes.append(selected_count)\n",
    "            episode_f1_scores.append(reward)\n",
    "            \n",
    "            if reward > best_reward:\n",
    "                best_reward = reward\n",
    "                best_selection = action.copy()\n",
    "                best_episode = episode\n",
    "            \n",
    "            episode_best_rewards.append(best_reward)\n",
    "            \n",
    "            loss = agent.replay()\n",
    "            \n",
    "            if episode % 25 == 0:\n",
    "                agent.update_target_network()\n",
    "            \n",
    "            # F1 learning curve evaluation (uses independent validation/test split)\n",
    "            if episode % f1_curve_frequency == 0:\n",
    "                selected_indices = np.where(action == 1)[0]\n",
    "                validation_f1, test_f1 = evaluator.evaluate_ensemble_for_learning_curve(selected_indices, fold_idx)\n",
    "                episode_validation_f1.append(validation_f1)\n",
    "                episode_test_f1.append(test_f1)\n",
    "                f1_evaluation_episodes.append(episode)\n",
    "            \n",
    "            # Progress reporting\n",
    "            if episode % evaluation_frequency == 0:\n",
    "                selected_count = int(np.sum(best_selection))\n",
    "                print(f\"Fold {fold_idx + 1} | Episode {episode:4d} | Best F1: {best_reward:.4f} | \"\n",
    "                      f\"Size: {selected_count:2d} | Current F1: {reward:.4f} | Îµ: {agent.epsilon:.3f}\")\n",
    "        \n",
    "        # Store fold results\n",
    "        all_fold_best_selections.append(best_selection)\n",
    "        all_fold_best_rewards.append(best_reward)\n",
    "        all_fold_agents.append(agent)\n",
    "        \n",
    "        # Store plotting data\n",
    "        all_fold_rewards.append(episode_rewards)\n",
    "        all_fold_best_rewards_plot.append(episode_best_rewards)\n",
    "        all_fold_f1_scores.append(episode_f1_scores)\n",
    "        all_fold_sizes.append(episode_sizes)\n",
    "        all_fold_validation_f1.append(episode_validation_f1)\n",
    "        all_fold_test_f1.append(episode_test_f1)\n",
    "        all_evaluation_episodes.append(f1_evaluation_episodes)\n",
    "        \n",
    "        # Store retrained models if this is the best fold so far\n",
    "        if best_reward == max(all_fold_best_rewards):\n",
    "            best_fold_retrained_models = retrained_models\n",
    "        \n",
    "        print(f\"\\nâœ… Fold {fold_idx + 1} completed! Best F1: {best_reward:.4f} at episode {best_episode}\")\n",
    "    \n",
    "    # Select best ensemble based on highest performance\n",
    "    best_fold_idx = np.argmax(all_fold_best_rewards)\n",
    "    best_overall_selection = all_fold_best_selections[best_fold_idx]\n",
    "    best_overall_reward = all_fold_best_rewards[best_fold_idx]\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"10-FOLD CROSS-VALIDATION COMPLETED\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Best fold: {best_fold_idx + 1}\")\n",
    "    print(f\"Best ensemble F1 score: {best_overall_reward:.4f}\")\n",
    "    print(f\"Average F1 across folds: {np.mean(all_fold_best_rewards):.4f} Â± {np.std(all_fold_best_rewards):.4f}\")\n",
    "    \n",
    "    # Create all required visualizations (single aggregated curves)\n",
    "    print(\"\\nCreating aggregated visualization plots...\")\n",
    "    \n",
    "    # 1. Training reward plots with aggregated convergence\n",
    "    create_aggregated_ensemble_training_plots(all_fold_rewards, all_fold_best_rewards_plot, \n",
    "                                         all_fold_f1_scores, all_fold_sizes)\n",
    "    \n",
    "    # 2. DQN learning plots (aggregated Loss, Epsilon, Q-Value curves)\n",
    "    create_aggregated_dqn_learning_plots(all_fold_agents, all_fold_f1_scores)\n",
    "    \n",
    "    # 3. F1 learning curves (aggregated Validation vs Test curves)\n",
    "    if len(all_fold_validation_f1[0]) > 0:\n",
    "        create_aggregated_f1_learning_curve(all_fold_validation_f1, all_fold_test_f1, all_evaluation_episodes)\n",
    "    \n",
    "    # Create final evaluator with best fold's retrained models for external evaluation\n",
    "    final_evaluator = TenFoldEnsembleEvaluator(best_fold_retrained_models, combined_datasets, fold_datasets)\n",
    "    \n",
    "    return best_overall_selection, best_overall_reward, all_fold_best_selections, all_fold_best_rewards, final_evaluator, external_datasets\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION WITH 10-FOLD CV\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"10-FOLD CV DATA FLOW WITH PROPER SEPARATION\")\n",
    "print(f\"{'='*70}\")\n",
    "print(\"1. COMBINED DATASET: Merge original train + test data\")\n",
    "print(\"2. 10-FOLD SPLITS: Stratified splits (90% train, 10% test per fold)\")\n",
    "print(\"3. TRAINING SPLIT (90%):\")\n",
    "print(\"   - Model Training (70%): Retrain 36 models on each fold\")\n",
    "print(\"   - DQN Validation (10%): Calculate DQN rewards\")\n",
    "print(\"   - LC Validation (10%): Learning curve validation\")\n",
    "print(\"4. TEST SPLIT (10%): Learning curve test\")\n",
    "print(\"5. STATE: Only F1 score (1 feature)\")\n",
    "print(\"6. FINAL EVALUATION: External data (untouched)\")\n",
    "\n",
    "# Train with 10-fold cross-validation (models retrained on each fold)\n",
    "best_selection, best_reward, all_fold_selections, all_fold_best_rewards, evaluator, external_datasets = train_10fold_ensemble_dqn(\n",
    "    original_model_templates, combined_datasets, external_datasets, \n",
    "    episodes=1000, evaluation_frequency=50, f1_curve_frequency=1,\n",
    "    model_training_epochs=200  # Epochs for retraining models on each fold\n",
    ")\n",
    "\n",
    "# Extract selected models\n",
    "selected_model_indices = np.where(best_selection == 1)[0].tolist()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"OPTIMAL ENSEMBLE FOUND (10-FOLD CV)\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Selected Model Indices: {selected_model_indices}\")\n",
    "print(f\"Ensemble Size: {len(selected_model_indices)}\")\n",
    "print(f\"Best Ensemble F1 Score: {best_reward:.4f}\")\n",
    "print(f\"Cross-validation F1 Mean: {np.mean(all_fold_best_rewards):.4f} Â± {np.std(all_fold_best_rewards):.4f}\")\n",
    "\n",
    "# Show detailed model-dataset mapping\n",
    "print(f\"\\nModel-Dataset Combinations:\")\n",
    "group_counts = [0, 0, 0]\n",
    "for idx in selected_model_indices:\n",
    "    if 0 <= idx <= 11:\n",
    "        group_idx = 0\n",
    "        model_in_group = idx + 1\n",
    "    elif 12 <= idx <= 23:\n",
    "        group_idx = 1\n",
    "        model_in_group = (idx - 12) + 1\n",
    "    else:\n",
    "        group_idx = 2\n",
    "        model_in_group = (idx - 24) + 1\n",
    "    \n",
    "    dataset_group = group_idx + 1\n",
    "    group_counts[group_idx] += 1\n",
    "    print(f\"   Model {model_in_group:2d} from Dataset Group {dataset_group} (Global Index: {idx})\")\n",
    "\n",
    "print(f\"\\nGroup Distribution: Group1={group_counts[0]}, Group2={group_counts[1]}, Group3={group_counts[2]}\")\n",
    "\n",
    "# Final evaluation on external validation data\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FINAL EVALUATION ON EXTERNAL VALIDATION DATA\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Direct voting ensemble evaluation on external data\n",
    "voting_results = evaluate_direct_voting_ensemble_on_external_data(evaluator, selected_model_indices, external_datasets)\n",
    "\n",
    "if voting_results:\n",
    "    print(f\"\\nâœ… 10-FOLD CV DIRECT VOTING ENSEMBLE COMPLETED\")\n",
    "    print(f\"   - Total models voting: {voting_results['total_models']}\")\n",
    "    print(f\"   - F1 Score: {voting_results['f1_score']:.4f}\")\n",
    "    print(f\"   - Accuracy: {voting_results['accuracy']:.4f}\")\n",
    "    print(f\"   - ROC-AUC: {voting_results['roc_auc']:.4f}\")\n",
    "    print(f\"   - PR-AUC: {voting_results['pr_auc']:.4f}\")\n",
    "    \n",
    "    # Performance comparison across folds\n",
    "    cv_f1 = np.mean(all_fold_best_rewards)\n",
    "    cv_std = np.std(all_fold_best_rewards)\n",
    "    voting_f1 = voting_results['f1_score']\n",
    "    \n",
    "    print(f\"\\nPERFORMANCE COMPARISON:\")\n",
    "    print(f\"   10-Fold CV F1 (mean Â± std):       {cv_f1:.4f} Â± {cv_std:.4f}\")\n",
    "    print(f\"   Best Fold F1:                     {best_reward:.4f}\")\n",
    "    print(f\"   Direct Voting F1 (external):      {voting_f1:.4f}\")\n",
    "    \n",
    "    voting_gap = abs(best_reward - voting_f1)\n",
    "    print(f\"   Generalization Gap:                {voting_gap:.4f}\")\n",
    "    \n",
    "    if voting_gap < 0.05:\n",
    "        print(f\"   Generalization Quality: EXCELLENT\")\n",
    "    elif voting_gap < 0.10:\n",
    "        print(f\"   Generalization Quality: GOOD\")\n",
    "    else:\n",
    "        print(f\"   Generalization Quality: MODERATE\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FINAL SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Method: 10-Fold CV + DQN + Direct Voting\")\n",
    "print(f\"State representation: F1 score only (1 feature)\")\n",
    "print(f\"Models retrained: 10 times (once per fold)\")\n",
    "print(f\"Ensemble size: {len(selected_model_indices)} models\")\n",
    "print(f\"CV F1 score: {cv_f1:.4f} Â± {cv_std:.4f}\")\n",
    "print(f\"External F1 score: {voting_results['f1_score']:.4f}\" if voting_results else \"N/A\")\n",
    "print(f\"External ROC-AUC: {voting_results['roc_auc']:.4f}\" if voting_results else \"N/A\")\n",
    "print(f\"External PR-AUC: {voting_results['pr_auc']:.4f}\" if voting_results else \"N/A\")\n",
    "\n",
    "print(f\"\\nâœ… BENEFITS:\")\n",
    "print(\"âœ“ Proper 10-fold cross-validation\")\n",
    "print(\"âœ“ Models retrained on each fold (no data leakage)\")\n",
    "print(\"âœ“ Simplified state: Only F1 score\")\n",
    "print(\"âœ“ Proper data separation (70%-10%-10%-10%)\")\n",
    "print(\"âœ“ Realistic performance estimates\")\n",
    "print(\"âœ“ Direct democratic voting\")\n",
    "print(\"âœ“ External validation on untouched data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd7ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f5a060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e65acd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e5b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0847fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b86d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c7b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56310cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5debb828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c326a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a3e259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffb9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e90db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0be252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e7086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996da4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c0613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f346caa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6c75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6febd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f12c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1979528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69d298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a7f539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac54270c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a710e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf620b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255e747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bbd03d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2b68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17568cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e6a8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec415182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5cd3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524556d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6474e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72aea0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca1916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6327e692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320754f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753bfe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f40684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a0ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782f9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf4b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c9c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5762144e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73d73d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759c7425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db5805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea75fda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819067a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdebb7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a3fd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68bb13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b4c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8700a52f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70554292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f4829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a75a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a25aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f035770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0fb717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4eaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8caa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39844c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9bef3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c4941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d25443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf32bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
